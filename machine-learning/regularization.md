# 正则化与稀疏性

## 正则化


#### LR正则化与数据先验分布的关系
正则化参数等价于对参数引入 先验分布，使得 模型复杂度 变小（缩小解空间），对于噪声以及 outliers 的鲁棒性增强（泛化能力）。整个最优化问题从贝叶斯观点来看是一种贝叶斯最大后验估计，其中 正则化项 对应后验估计中的 先验信息，损失函数对应后验估计中的似然函数，两者的乘积即对应贝叶斯最大后验估计的形式。 [LR正则化与数据先验分布的关系](https://note.youdao.com/ynoteshare1/index.html?id=2851b97199bcdc174001d72b1bec0372&type=note)


#### L1在0点处不可导怎么办？
可采用坐标轴下降、最小角回归法 [blog](https://www.cnblogs.com/pinard/p/6018889.html)


#### 模型稀疏的好处
+ 能解决「模型复杂度低，线上预测效果差；模型复杂度高，线上预测效果好，但需要的存储、时间资源也随之升高，无法保证RT和 QPS」之问题。这是比较显然的。稀疏的模型会大大减少预测时的内存和复杂度。绝大多数特征甚至不需要去采集。这样一来，从特征采集到预测运算整个步骤都能省下很多内存和计算复杂度。
+ 模型的稀疏与L1正则化不谋而合（见[谈谈 L1 与 L2-正则项](https://liam.page/2017/03/30/L1-and-L2-regularizer/)一文），这意味着运用L1正则化一方面可以使得模型变得稀疏，另一方面还能够降低模型过拟合的风险。
+ 稀疏性较好的模型，相对来说可解释性更好。
+ 模型响应灵敏。
