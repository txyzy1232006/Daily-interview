# 特征选择
在做数据分析的时候，特征的来源一般有两块，一块是业务已经整理好各种特征数据，我们需要去找出适合我们问题需要的特征；另一块是我们从业务特征中自己去寻找高级数据特征。

### 特征选择
##### 过滤法
1. 方差筛选。方差越大的特征，那么我们可以认为它是比较有用的。
2. 相关系数。这个主要用于输出连续值的监督学习算法中。我们分别计算所有训练集中各个特征与输出值之间的相关系数，设定一个阈值，选择相关系数较大的部分特征。
3. 假设检验，比如卡方检验。卡方检验可以检验某个特征分布和输出值分布之间的相关性。
4. 互信息，即从信息熵的角度分析各个特征和输出值之间的关系评分。
##### 包装法
最常用的包装法是递归消除特征法(recursive feature elimination,以下简称RFE)。递归消除特征法使用一个机器学习模型来进行多轮训练，每轮训练后，消除若干权值系数的对应的特征，再基于新的特征集进行下一轮训练。在sklearn中，可以使用RFE函数来选择特征。
##### 嵌入法
嵌入法也是用机器学习的方法来选择特征
1. L1正则化和L2正则化。常用的L1正则化和L2正则化来选择特征的基学习器是逻辑回归。
2. 决策树或GBDT

***
### 特征组合
##### 寻找高级特征的方法
若干项特征加和： 我们假设你希望根据每日销售额得到一周销售额的特征。你可以将最近的7天的销售额相加得到。
若干项特征之差： 假设你已经拥有每周销售额以及每月销售额两项特征，可以求一周前一月内的销售额。
若干项特征乘积： 假设你有商品价格和商品销量的特征，那么就可以得到销售额的特征。
若干项特征除商： 假设你有每个用户的销售额和购买的商品件数，那么就是得到该用户平均每件商品的销售额。

##### 怎样有效地找到组合特征？
1. 决策树
2. FM + L1 正则


##### 如何处理高维组合特征？
FM (双线性)
